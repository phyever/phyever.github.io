<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>

    <!--Description-->

    

    
        <meta name="description" content="Authors: Chen Wei*, Chi Zhang*, Jiachen Zou, Haotian Deng, Dietmar Heinke, Quanying Liu*Chen Wei and Chi Zhang contributed equally to this work.Date: "/>
    

    <!--Author-->
    
        <meta name="author" content="Jiachen Zou"/>
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering and Manipulating Human Perceptual Variability"/>
    

    <!--Open Graph Description-->
    
        <meta property="og:description" content="Authors: Chen Wei*, Chi Zhang*, Jiachen Zou, Haotian Deng, Dietmar Heinke, Quanying Liu*Chen Wei and Chi Zhang contributed equally to this work.Date: "/>
    

    <!--Open Graph Site Name-->
        <meta property="og:site_name" content="Hi, this is Jiachen"/>

    <!--Type page-->
    
        <meta property="og:type" content="article"/>
    

    <!--Page Cover-->
    
    
        <meta property="og:image" content="http://phyever.github.ioimg/home-bg.jpg"/>
    

        <meta name="twitter:card" content="summary_large_image"/>

    

    
        <meta name="twitter:image" content="http://phyever.github.ioimg/home-bg.jpg"/>
    

    <!-- Title -->
    
    <title>Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering and Manipulating Human Perceptual Variability - Hi, this is Jiachen</title>

    <!-- Bootstrap Core CSS -->
    <link href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" rel="stylesheet"/>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/style.css">


    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/>
    <link href="//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css"/>
    <link href="//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css"/>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet"/>

    <!-- Google Analytics -->
    


    <!-- favicon -->
    

<meta name="generator" content="Hexo 6.3.0"></head>


<body>

    <!-- Menu -->
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Jiachen Zou's website</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                
                    <li>
                        <a href="/">
                            
                                Home
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/experience">
                            
                                Experience
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/publications">
                            
                                Publications
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/contact">
                            
                                Contact
                            
                        </a>
                    </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>

    <!-- Main Content -->
    <!-- Page Header -->
<!-- Set your background image for this header in your post front-matter: cover -->

<header class="intro-header" style="background-image: url('/img/home-bg.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <h1>Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering and Manipulating Human Perceptual Variability</h1>
                    
                    <span class="meta">
                        <!-- Date and Author -->
                        
                        
                            2024-10-02
                        
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Tags and categories -->
           

            <!-- Gallery -->
            

            <!-- Post Main Content -->
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <p>Authors: Chen Wei*, Chi Zhang*, <strong>Jiachen Zou</strong>, Haotian Deng, Dietmar Heinke, Quanying Liu<br><small>*Chen Wei and Chi Zhang contributed equally to this work.</small><br>Date: October 2, 2024<br>Supervisor: Quanying Liu, Dietmar Heinke</p>
<p><img src="/img/var_fig1.png" alt="varMNIST Motivation"></p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><strong>Motivation:</strong><br>Human perception varies with ambiguous stimuli, and ANNs struggle to capture this variability. Understanding it is key to predicting individual perception in uncertain situations. This study explores whether generating images based on ANN perceptual boundaries can reveal and manipulate human perceptual variability.</p>
<p><strong>Method:</strong><br>We present a paradigm for studying human perceptual variability through image generation: <em>1) Generating &amp; labeling</em>: Images sampled from the decision boundaries of ANNs are used in human behavioral experiments to construct a high-variability dataset, varMNIST. <em>2) Predicting</em>: Human behavioral data are used to finetune models, aligning them with human perceptual variability at both the group level and individual level. <em>3) Manipulating</em>: Individual finetuned models are leveraged as adversarial classifiers to generate new images that amplify perceptual differences between individuals.</p>
<p><strong>Contribution:</strong>  </p>
<ul>
<li>A novel generative approach to probe human perception.  </li>
<li>Aligning human and ANN perceptual variability.  </li>
<li>Revealing and manipulating individual decisions.</li>
</ul>
<!-- This adds space between the figures -->
<div style="margin-top: 10px;"></div>

<h1 id="Collecting-Human-Perceptual-Variability"><a href="#Collecting-Human-Perceptual-Variability" class="headerlink" title="Collecting Human Perceptual Variability"></a>Collecting Human Perceptual Variability</h1><p><strong>Generating images by sampling from the perceptual boundary of ANNs:</strong><br>We sampled images along ANN decision boundaries to induce high perceptual variability using two methods:</p>
<ul>
<li><em>Uncertainty Guidance</em>: Maximizes entropy in an ANN’s classification to generate ambiguous images near its decision boundary.</li>
<li><em>Controversial Guidance</em>: Maximizes the KL divergence between two ANN models, producing images that highlight differences in their classifications.</li>
</ul>
<p><strong>Improving generative quality by digit judgment surrogate:</strong><br>We conducted a digit judgment experiment, using participants’ judgments on whether generated images looked like handwritten digits to train a digit judgment proxy, which is then used to guide image generation.</p>
<figure>
  <img src="/img/var_fig2.jpg" alt="framework">
  <figcaption style="text-align: center; color: #004400; font-weight: bold;">Figure 1: Generating images to elicit human perceptual variability.</figcaption>
</figure>

<!-- This adds space between the figures -->
<div style="margin-top: 10px;"></div>

<p><strong>Measuring Human Perceptual Variability by Recognition Experiment:</strong><br>We used the images synthesized using the two guidance methods, ANN perceptual boundary sampling and digit judgment surrogate, for the digit recognition human experiment.  A total of 19,952 images were used, with 123,000 trials conducted across 246 participants, resulting in the high perceptual variability dataset varMNIST.</p>
<figure>
  <img src="/img/var_fig3.png" alt="framework">
  <figcaption style="text-align: center; color: #004400; font-weight: bold;">Figure 2: Quantitative analysis of varMNIST.</figcaption>
</figure>

<!-- This adds space between the figures -->
<div style="margin-top: 30px;"></div>

<h1 id="Predicting-Human-Perceptual-Variability"><a href="#Predicting-Human-Perceptual-Variability" class="headerlink" title="Predicting Human Perceptual Variability"></a>Predicting Human Perceptual Variability</h1><!-- This adds space between the figures -->
<div style="margin-top: 10px;"></div>

<p><strong>Fine-tuning Models for Human Alignment:</strong></p>
<ul>
<li>We used a mixed training approach to fine-tune models, combining MNIST and varMNIST datasets for group training and varMNIST-i, varMNIST, and MNIST for individual training. Fine-tuning improved model accuracy, with individual fine-tuning providing additional gains.</li>
</ul>
<p><strong>Different Classifiers Show Varying Fine-tuning Performance:</strong></p>
<ul>
<li>Fine-tuning enhanced the performance of most classifiers, with VIT and MLP showing the largest improvements, while LRM exhibited the weakest adaptability.</li>
</ul>
<p><strong>Performance across Images with Varying Entropy Levels:</strong>  </p>
<ul>
<li>Fine-tuned models outperformed the base model across all task difficulties, with individual fine-tuning providing the most benefit for more challenging (high-entropy) samples, highlighting the model’s improved adaptability to complex stimuli.</li>
</ul>
<figure>
  <img src="/img/var_fig4.png" alt="framework">
  <figcaption style="text-align: center; color: #004400; font-weight: bold;">Figure 3: Human alignment results. (a) Model accuracy comparison. (b) Classifier fine-tuning performance. (c) Human-model entropy correlation. (d) Performance across entropy levels.</figcaption>
</figure>

<!-- This adds space between the figures -->
<div style="margin-top: 30px;"></div>

<h1 id="Manipulating-human-perceptual-variablity"><a href="#Manipulating-human-perceptual-variablity" class="headerlink" title="Manipulating human perceptual variablity"></a>Manipulating human perceptual variablity</h1><p><strong>Experimental Paradigm:</strong></p>
<ul>
<li>We tested if fine-tuned individual models could amplify perceptual differences and guide decisions. In the first round, 500 varMNIST samples were used to fine-tune individual models. In the second round, controversial stimuli generated from these models were presented to pairs of participants to evaluate if they could guide decision directions.</li>
</ul>
<p><strong>Manipulation Results:</strong></p>
<ul>
<li><p><em>Guidance Outcome</em> (success, bias, or failure): Individual fine-tuning improved the success rate by 3%, reduced failures by 4%, and increased bias by 1% compared to varMNIST, even with a small sample size.</p>
</li>
<li><p><em>Targeted Ratio</em> (the proportion of trials where participants’ choices aligned with the guidance direction): The targeted ratio improved by 12%, showing that fine-tuning enhanced the model’s ability to guide decisions more effectively and precisely.</p>
</li>
</ul>
<figure>
  <img src="/img/var_fig5.png" alt="framework">
  <figcaption style="text-align: center; color: #004400; font-weight: bold;">Figure 4: Manipulation analysis. (a) Experiment process. (b) Guidance outcomes. (c) Guidance success rates. (d) Targeted ratios.</figcaption>
</figure>

<!-- This adds space between the figures -->
<div style="margin-top: 30px;"></div>

<h1 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h1><p><strong>Key Findings:</strong>  </p>
<ul>
<li>Eliciting Human Perceptual Variability Through Generated Samples.</li>
<li>Achieving Individual Alignment by Predicting Human Perceptual Variability.</li>
<li>Revealing and Manipulating Perceptual Variability Using Individual Models.</li>
</ul>
<p><strong>Future Works:</strong>  </p>
<ul>
<li>Expanding the dataset to natural images and diverse participants will better capture human variability.  </li>
<li>Further improvements are needed in AI-human alignment using optimal experimental design.</li>
</ul>
<p>This paper has been published in ICML 2025.</p>


                
            </div>

            <!-- Comments -->
            
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    


                </div>
            
        </div>
    </div>
</article>

    <!-- Footer -->
    <hr />

<!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    

                    


                    

                    

                    
                </ul>
                <p class="copyright text-muted">&copy; 2025 Jiachen Zou<br></p>
            </div>
        </div>
    </div>
</footer>


    <!-- After footer scripts -->
    
<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Bootstrap -->
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Disqus Comments -->



</body>

</html>